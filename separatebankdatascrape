import requests
from bs4 import BeautifulSoup
import pandas as pd

base_url = "https://www.jpmorganchase.com"
news_url = base_url + "/news-stories/news"

def get_news_content(article_url):
    try:
        if not article_url.startswith('http'):
            article_url = base_url + article_url
        response = requests.get(article_url)
        soup = BeautifulSoup(response.content, 'html.parser')
        content = soup.find('div', class_='article__body__text').get_text(strip=True)
        return content
    except Exception as e:
        print(f"Error processing article at {article_url}: {e}")
        return None

def scrape_news(url):
    response = requests.get(url)
    soup = BeautifulSoup(response.content, 'html.parser')
    news_data = []

    articles = soup.find_all('h3', {'data-json-key': 'title'})
    for article in articles:
        headline = article.get_text(strip=True)
        link_tag = article.find_next('div', class_='callout').find('a', {'data-json-key': 'href'})
        date_tag = article.find_next('div', class_='date').find('span')
        
        if link_tag and date_tag:
            news_link = link_tag['href']
            date = date_tag.get_text(strip=True)
            content = get_news_content(news_link)
            if content:
                news_data.append({'Date': date, 'Headline': headline, 'Content': content, 'Source': base_url + news_link})

    return news_data

news = scrape_news(news_url)
df = pd.DataFrame(news)
df.to_csv('jpv22.csv', index=False)

